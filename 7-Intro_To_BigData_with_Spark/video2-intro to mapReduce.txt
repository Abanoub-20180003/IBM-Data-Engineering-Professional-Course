Welcome to Introduction to MapReduce. After watching this video, you will be able
to: Explain the terms Map and Reduce in MapReduce, describe why we use MapReduce, list the components of MapReduce, outline examples of common use cases of MapReduce. What is MapReduce? MapReduce is a programming pattern that enables
massive scalability across hundreds or thousands of servers in a Hadoop cluster. As the processing component, MapReduce is
the heart of Apache Hadoop. MapReduce is a processing technique and a
program model for distributed computing, it is based on Java. Distributed computing is a system or machine
with multiple components located on different machines. Each component has its own job, but the components
communicate with each other to run as one system to the end user." The MapReduce algorithm consists of two important
tasks - Map and Reduce. Many MapReduce programs are written in Java. MapReduce
can also be coded in C++, Python, Ruby, R and so on. As the name suggests, the MapReduce framework
contains two tasks, Map and Reduce. Map takes in an input file and performs some mapping tasks by processing
and extracting important data information into a key value pairs and these are the preliminary
output list. Some more reorganization goes on before the
preliminary output is sent to the Reducer. The Reducer works with multiple map functions
and aggregates the pairs using their keys to produce a final output. MapReduce keeps track of its tasks by creating
unique keys to ensure that all the processes are solving the same problem. Let us look at the framework visually. First, we have the Map step, which takes a
set of data and converts it into another set of data, where individual elements are broken
down into key/value pairs. The key is the name, and the value is the
content. The input data is a file that is saved in
the Hadoop file system called HDFS. Now let’s assume we have an input file that
contains names of people, and we would like to do a word count on the unique name occurrences. First, the data is split into the following
four files, each of them in key value pair and are worked on separately. For example, for the first split line for Teju and Briana, we have two key value pairs
with one occurrence in each file, and it will do the same for all of key value pairs. We then have the reducer; the reducer processes
the data that comes from the map. After processing, it produces a new set of
outputs, which will be stored in the HDFS. The Reducer starts with shuffling. Shuffling sorts the key and a list of values
in a list, for example, you will see the Key Teju and the corresponding list of values
from the previous step. We will have Teju [1, 1, 1], This is because
the name Teju occurred 3 times in the “Map” step. It does the same for the rest of the names,
counting how many times they appeared in the “Map” step. The Reducer layer then aggregates the values
in the list and saves them, then the final output is saved in an output file. The advantages of MapReduce is its ability
to allow for a high level of parallel jobs across multiple nodes. A node is an independent computer used for
processing and storing big volumes of data. In Hadoop we have two types of nodes, the
name node and the data node. Map reduce allows for splitting and running
independent tasks in parallel by dividing each task which in turn saves time. MapReduce is very flexible and can process
data that come in tabular and non-tabular forms. Therefore, MapReduce provides business value
to organizations regardless of how their data is structured. It also offers support for different languages
and provides a platform for analysis, data warehousing and more. MapReduce has a couple of use cases and here
we have some of them displayed. MapReduce can be used for social media platforms
like LinkedIn and Instagram to analyze who visited, viewed, and interacted with your profile posts. Map reduce is used by Netflix to recommend
movies based on what you have watched in the past by using the user's interests. It is also used in financial institutions
like banks and credit card companies to flag and detect anomalies in user transactions. It can also be used in the advertisement industry
to understand a user’s behavior by how they engage with ads. Google ads work by using MapReduce to understand
the engagement of users with an ad. In this video, you have learned that: MapReduce is a framework used in Parallel
Computing, it contains two major tasks: Map and Reduce. Map processes data into Key Value pairs, sorts
and organizes the data. The Reducer aggregates and computes a set
of results and produces a final output. It is flexible for all data types like structured
and unstructured data and can be applied to multiple industries such
as social media, entertainment, and many more.